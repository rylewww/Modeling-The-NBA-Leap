{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV,\\\n",
    "cross_val_score, RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.metrics import f1_score, confusion_matrix, recall_score, precision_score, accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, f1_score, recall_score, confusion_matrix, classification_report, make_scorer\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn import tree \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('Final_NBA_Seasons1-3_1977_final.csv', index_col = 0)\n",
    "# df_final.set_index('Player', inplace = True)\n",
    "full_df = pd.read_csv('Final_NBA_PLayers_updated.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding in rookie season to our final data set, through strech goal year-over-year analysis it showed that player age, season count and statistics fluctuate year over year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.C. Green\\greenac01</td>\n",
       "      <td>1985-86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A.J. Bramlett\\bramlaj01</td>\n",
       "      <td>1999-00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A.J. English\\engliaj01</td>\n",
       "      <td>1990-91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A.J. Guyton\\guytoaj01</td>\n",
       "      <td>2000-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A.J. Hammons\\hammoaj01</td>\n",
       "      <td>2016-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Player   Season\n",
       "0      A.C. Green\\greenac01  1985-86\n",
       "16  A.J. Bramlett\\bramlaj01  1999-00\n",
       "17   A.J. English\\engliaj01  1990-91\n",
       "19    A.J. Guyton\\guytoaj01  2000-01\n",
       "22   A.J. Hammons\\hammoaj01  2016-17"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rookie_df = full_df[full_df['season_count'] == 1]\n",
    "rookie_df = rookie_df[['Player','Season']]\n",
    "# rookie_df.set_index('Player', inplace = True)\n",
    "rookie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging rookie season into final dataset\n",
    "df = df_final.merge(rookie_df, how = 'left', on = 'Player')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>...</th>\n",
       "      <th>USG_1-2</th>\n",
       "      <th>USG_2-3</th>\n",
       "      <th>VORP_1-2</th>\n",
       "      <th>VORP_2-3</th>\n",
       "      <th>target</th>\n",
       "      <th>Qualified</th>\n",
       "      <th>Season</th>\n",
       "      <th>year_split</th>\n",
       "      <th>award_year</th>\n",
       "      <th>season_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A.C. Green\\greenac01</td>\n",
       "      <td>243</td>\n",
       "      <td>137.0</td>\n",
       "      <td>6418.0</td>\n",
       "      <td>847</td>\n",
       "      <td>1615</td>\n",
       "      <td>846</td>\n",
       "      <td>1602</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1985-86</td>\n",
       "      <td>[1985, 86]</td>\n",
       "      <td>86</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A.J. Price\\priceaj01</td>\n",
       "      <td>150</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2228.0</td>\n",
       "      <td>318</td>\n",
       "      <td>848</td>\n",
       "      <td>191</td>\n",
       "      <td>437</td>\n",
       "      <td>127.0</td>\n",
       "      <td>411.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2009-10</td>\n",
       "      <td>[2009, 10]</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Brooks\\brookaa01</td>\n",
       "      <td>213</td>\n",
       "      <td>117.0</td>\n",
       "      <td>5525.0</td>\n",
       "      <td>984</td>\n",
       "      <td>2339</td>\n",
       "      <td>626</td>\n",
       "      <td>1396</td>\n",
       "      <td>358.0</td>\n",
       "      <td>943.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007-08</td>\n",
       "      <td>[2007, 08]</td>\n",
       "      <td>08</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Gordon\\gordoaa01</td>\n",
       "      <td>205</td>\n",
       "      <td>117.0</td>\n",
       "      <td>4958.0</td>\n",
       "      <td>760</td>\n",
       "      <td>1652</td>\n",
       "      <td>628</td>\n",
       "      <td>1195</td>\n",
       "      <td>132.0</td>\n",
       "      <td>457.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-15</td>\n",
       "      <td>[2014, 15]</td>\n",
       "      <td>15</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Gray\\grayaa01</td>\n",
       "      <td>149</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1639.0</td>\n",
       "      <td>226</td>\n",
       "      <td>453</td>\n",
       "      <td>226</td>\n",
       "      <td>451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007-08</td>\n",
       "      <td>[2007, 08]</td>\n",
       "      <td>08</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 221 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Player    G     GS      MP   FG   FGA   2P   2PA     3P  \\\n",
       "0    A.C. Green\\greenac01  243  137.0  6418.0  847  1615  846  1602    1.0   \n",
       "1    A.J. Price\\priceaj01  150    3.0  2228.0  318   848  191   437  127.0   \n",
       "2  Aaron Brooks\\brookaa01  213  117.0  5525.0  984  2339  626  1396  358.0   \n",
       "3  Aaron Gordon\\gordoaa01  205  117.0  4958.0  760  1652  628  1195  132.0   \n",
       "4     Aaron Gray\\grayaa01  149   19.0  1639.0  226   453  226   451    0.0   \n",
       "\n",
       "     3PA  ...  USG_1-2  USG_2-3  VORP_1-2  VORP_2-3  target  Qualified  \\\n",
       "0   13.0  ...      0.0      0.0       1.5      -0.2       0        1.0   \n",
       "1  411.0  ...      0.0     -5.0      -0.5       0.3       0        1.0   \n",
       "2  943.0  ...      1.1      2.8       0.3       1.3       0        1.0   \n",
       "3  457.0  ...      1.8      2.8       1.6      -0.8       0        1.0   \n",
       "4    2.0  ...     -7.5      1.9       0.0       0.3       0        1.0   \n",
       "\n",
       "    Season  year_split  award_year  season_year  \n",
       "0  1985-86  [1985, 86]          86         1985  \n",
       "1  2009-10  [2009, 10]          10         2009  \n",
       "2  2007-08  [2007, 08]          08         2007  \n",
       "3  2014-15  [2014, 15]          15         2014  \n",
       "4  2007-08  [2007, 08]          08         2007  \n",
       "\n",
       "[5 rows x 221 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#breaking season and coverting into integer to be processed in model\n",
    "df['year_split'] = df['Season'].str.split('-')\n",
    "df['award_year'] = [x[1] for x in df['year_split']]\n",
    "df['season_year'] = [x[0] for x in df['year_split']]\n",
    "df['season_year'] = df['season_year'].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>2P</th>\n",
       "      <th>FT</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PTS</th>\n",
       "      <th>roy</th>\n",
       "      <th>...</th>\n",
       "      <th>ORtg_3</th>\n",
       "      <th>DRtg_3</th>\n",
       "      <th>OWS_3</th>\n",
       "      <th>DWS_3</th>\n",
       "      <th>WS/48_3</th>\n",
       "      <th>VORP_3</th>\n",
       "      <th>VORP_1-2</th>\n",
       "      <th>VORP_2-3</th>\n",
       "      <th>season_year</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6418.0</td>\n",
       "      <td>847</td>\n",
       "      <td>846</td>\n",
       "      <td>615</td>\n",
       "      <td>1706.0</td>\n",
       "      <td>231</td>\n",
       "      <td>206.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>2310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.144</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2228.0</td>\n",
       "      <td>318</td>\n",
       "      <td>191</td>\n",
       "      <td>142</td>\n",
       "      <td>221.0</td>\n",
       "      <td>303</td>\n",
       "      <td>84.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5525.0</td>\n",
       "      <td>984</td>\n",
       "      <td>626</td>\n",
       "      <td>436</td>\n",
       "      <td>428.0</td>\n",
       "      <td>759</td>\n",
       "      <td>128.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>2762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.091</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4958.0</td>\n",
       "      <td>760</td>\n",
       "      <td>628</td>\n",
       "      <td>329</td>\n",
       "      <td>1081.0</td>\n",
       "      <td>311</td>\n",
       "      <td>145.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1981</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>107.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1639.0</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>110</td>\n",
       "      <td>494.0</td>\n",
       "      <td>109</td>\n",
       "      <td>44.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>562</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>115.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MP   FG   2P   FT     TRB  AST    STL    TOV   PTS  roy  ...  ORtg_3  \\\n",
       "0  6418.0  847  846  615  1706.0  231  206.0  321.0  2310  0.0  ...   119.0   \n",
       "1  2228.0  318  191  142   221.0  303   84.0  144.0   905  0.0  ...   100.0   \n",
       "2  5525.0  984  626  436   428.0  759  128.0  401.0  2762  0.0  ...   108.0   \n",
       "3  4958.0  760  628  329  1081.0  311  145.0  193.0  1981  0.0  ...   107.0   \n",
       "4  1639.0  226  226  110   494.0  109   44.0  115.0   562  0.0  ...   115.0   \n",
       "\n",
       "   DRtg_3  OWS_3  DWS_3  WS/48_3  VORP_3  VORP_1-2  VORP_2-3  season_year  \\\n",
       "0   106.0    4.5    3.4    0.144     1.5       1.5      -0.2         1985   \n",
       "1   106.0    0.2    0.5    0.063     0.1      -0.5       0.3         2009   \n",
       "2   112.0    3.9    1.6    0.091     1.9       0.3       1.3         2007   \n",
       "3   111.0    2.0    1.7    0.077     0.6       1.6      -0.8         2014   \n",
       "4   106.0    0.5    0.4    0.142     0.1       0.0       0.3         2007   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final columns selected after correlation analysis\n",
    "cols = ['MP','FG','2P','FT','TRB','AST','STL','TOV','PTS','roy','all_rookie_1','all_rookie_2','WS_1','GS_1','MP_1','PTS_1','ppg_1','apg_1','rpg_1','spg_1','bpg_1',\n",
    "        'tpg_1','ftpg_1','PER_1','WS/48_1','VORP_1','WS_2','GS_2','MP_2','ppg_2','apg_2','rpg_2','spg_2','bpg_2','tpg_2','ftpg_2','PER_2','USG%_2',\n",
    "        'ORtg_2','DRtg_2','OWS_2','DWS_2','WS/48_2','VORP_2','WS_3','GS_3','MP_3','PTS_3','TS%_3','ppg_3','apg_3','rpg_3','spg_3','bpg_3','tpg_3','ftpg_3','PER_3','USG%_3',\n",
    "        'ORtg_3','DRtg_3','OWS_3','DWS_3','WS/48_3','VORP_3','VORP_1-2','VORP_2-3','season_year','target',]\n",
    "\n",
    "df = df[cols]\n",
    "df = df.fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to call for evaluation of each model\n",
    "def metrics_score(train_preds, y_train, test_preds, y_test):\n",
    "    print(f\"Training Accuracy:\\t{accuracy_score(y_train, train_preds):.4}\",\n",
    "          f\"\\tTesting Accuracy:\\t{accuracy_score(y_test, test_preds):.4}\")\n",
    "    print(f\"Training Precision:\\t{precision_score(y_train, train_preds):.4}\",\n",
    "          f\"\\tTesting Precision:\\t{precision_score(y_test, test_preds):.4}\")\n",
    "    print(f\"Training Recall:\\t{recall_score(y_train, train_preds):.4}\",\n",
    "          f\"\\tTesting Recall:\\t\\t{recall_score(y_test, test_preds):.4}\")\n",
    "    print(f\"Training F1:\\t\\t{f1_score(y_train, train_preds):.4}\",\n",
    "          f\"\\tTesting F1:\\t\\t{f1_score(y_test, test_preds):.4}\")\n",
    "#defining which metric our models will focus on\n",
    "scorer = make_scorer(precision_score, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting our dataset into training and testing\n",
    "X = df.drop(columns = 'target')\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, train_size= .8, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_scaled = StandardScaler()\n",
    "\n",
    "nba_scaled.fit(X_train)\n",
    "X_train_sc = pd.DataFrame(nba_scaled.transform(X_train), index = X_train.index, columns = X_train.columns)\n",
    "X_test_sc = pd.DataFrame(nba_scaled.transform(X_test), index = X_test.index, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(class_weight = 'balanced', random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', random_state=42)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\t1.0 \tTesting Accuracy:\t0.9373\n",
      "Training Precision:\t1.0 \tTesting Precision:\t0.6\n",
      "Training Recall:\t1.0 \tTesting Recall:\t\t0.3333\n",
      "Training F1:\t\t1.0 \tTesting F1:\t\t0.4286\n"
     ]
    }
   ],
   "source": [
    "rfbase_train_preds = rf.predict(X_train_sc)\n",
    "rfbase_test_preds = rf.predict(X_test_sc)\n",
    "metrics_score(rfbase_train_preds, y_train, rfbase_test_preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Random Forest Model w/ all features is way too overfit on the training set and does not perform well on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest RFE Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['PTS', 'WS_2', 'PER_2', 'VORP_2', 'PER_3', 'VORP_3'], dtype='object')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_rf = RFECV(estimator=RandomForestClassifier(class_weight = 'balanced', random_state = 42), step = 1, cv = 3, scoring = 'precision', n_jobs = -1, verbose = 1)\n",
    "rfe_rf.fit(X_train_sc, y_train)\n",
    "X_train_sc.columns[rfe_rf.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cols =['PTS', 'WS_2', 'PER_2', 'VORP_2', 'PER_3', 'VORP_3', 'season_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Baseline w/ RFE + Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', random_state=42)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(class_weight = 'balanced', random_state = 42)\n",
    "rf.fit(X_train_sc[rf_cols], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\t1.0 \tTesting Accuracy:\t0.9373\n",
      "Training Precision:\t1.0 \tTesting Precision:\t0.5714\n",
      "Training Recall:\t1.0 \tTesting Recall:\t\t0.4444\n",
      "Training F1:\t\t1.0 \tTesting F1:\t\t0.5\n"
     ]
    }
   ],
   "source": [
    "rfbaserfe_train_preds = rf.predict(X_train_sc[rf_cols])\n",
    "rfbaserfe_test_preds = rf.predict(X_test_sc[rf_cols])\n",
    "metrics_score(rfbaserfe_train_preds, y_train, rfbaserfe_test_preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline model with RFE selected features continues to be overfit to the training set and underperform on the validation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Grid Search w/ RFE Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cols =['PTS', 'WS_2', 'PER_2', 'VORP_2', 'PER_3', 'VORP_3', 'season_year']\n",
    "\n",
    "params = { \n",
    "    'n_estimators': [10, 25, 50, 100, 200, 500],\n",
    "    'max_features': ['sqrt', 'auto', 'log2'],\n",
    "    'max_depth' : [2,4,6,8,10,12,15,20],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "grid_search_RF = GridSearchCV(estimator=rf, param_grid=params, scoring=scorer, \n",
    "                              cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   34.6s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 4, 6, 8, 10, 12, 15, 20],\n",
       "                         'max_features': ['sqrt', 'auto', 'log2'],\n",
       "                         'n_estimators': [10, 25, 50, 100, 200, 500]},\n",
       "             scoring=make_scorer(precision_score, average=weighted), verbose=2)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_RF.fit(X_train_sc[rf_cols], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 6,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_RF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\t0.9833 \tTesting Accuracy:\t0.9529\n",
      "Training Precision:\t1.0 \tTesting Precision:\t0.75\n",
      "Training Recall:\t0.7639 \tTesting Recall:\t\t0.5\n",
      "Training F1:\t\t0.8661 \tTesting F1:\t\t0.6\n"
     ]
    }
   ],
   "source": [
    "rf_train_preds = grid_search_RF.best_estimator_.predict(X_train_sc[rf_cols])\n",
    "rf_test_preds = grid_search_RF.best_estimator_.predict(X_test_sc[rf_cols])\n",
    "metrics_score(rf_train_preds, y_train, rf_test_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.13861\n",
      "Feature: 1, Score: 0.10233\n",
      "Feature: 2, Score: 0.10827\n",
      "Feature: 3, Score: 0.12096\n",
      "Feature: 4, Score: 0.21247\n",
      "Feature: 5, Score: 0.24169\n",
      "Feature: 6, Score: 0.07567\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = grid_search_RF.best_estimator_.feature_importances_\n",
    "\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.xticks([0,1,2,3,4,5,6],['PTS', 'WS_2', 'PER_2', 'VORP_2', 'PER_3', 'VORP_3', 'season_year'], rotation = 15)\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.savefig('Feature_Importance_transparent',\n",
    "           transparent = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Random Forest Classifier Model\")\n",
    "\n",
    "plot_confusion_matrix(grid_search_RF, X_test_sc[rf_cols], y_test, ax=ax, cmap=\"YlGnBu\");\n",
    "\n",
    "plt.savefig('Confusion_updated',\n",
    "           transparent = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest RFE w/ Grid-search + SMOTE Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done 182 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 385 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 668 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1033 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [2, 4, 6, 8, 10, 12, 15, 20],\n",
       "                         'max_features': ['sqrt', 'auto', 'log2'],\n",
       "                         'n_estimators': [10, 25, 50, 100, 200, 500]},\n",
       "             scoring=make_scorer(precision_score, average=weighted), verbose=2)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE(random_state = 42)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train_sc[rf_cols], y_train.ravel())\n",
    "\n",
    "params = { \n",
    "    'n_estimators': [10, 25, 50, 100, 200, 500],\n",
    "    'max_features': ['sqrt', 'auto', 'log2'],\n",
    "    'max_depth' : [2,4,6,8,10,12,15,20],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state = 42)\n",
    "\n",
    "grid_search_RF_sm = GridSearchCV(estimator=rf, param_grid=params, scoring=scorer, \n",
    "                              cv = 5, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search_RF_sm.fit(X_train_res, y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 15,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_RF_sm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\t1.0 \tTesting Accuracy:\t0.9216\n",
      "Training Precision:\t1.0 \tTesting Precision:\t0.4643\n",
      "Training Recall:\t1.0 \tTesting Recall:\t\t0.7222\n",
      "Training F1:\t\t1.0 \tTesting F1:\t\t0.5652\n"
     ]
    }
   ],
   "source": [
    "rf_train_preds_sm = grid_search_RF_sm.best_estimator_.predict(X_train_res)\n",
    "rf_test_preds_sm = grid_search_RF_sm.best_estimator_.predict(X_test_sc[rf_cols])\n",
    "metrics_score(rf_train_preds_sm, y_train_res, rf_test_preds_sm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\t0.9558 \tTesting Accuracy:\t0.9373\n",
      "Training Precision:\t0.8 \tTesting Precision:\t0.5625\n",
      "Training Recall:\t0.5 \tTesting Recall:\t\t0.5\n",
      "Training F1:\t\t0.6154 \tTesting F1:\t\t0.5294\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight = 'balance', random_state = 42)\n",
    "lr.fit(X_train_sc, y_train)\n",
    "\n",
    "lrbase_train_preds = lr.predict(X_train_sc)\n",
    "lrbase_test_preds = lr.predict(X_test_sc)\n",
    "metrics_score(lrbase_train_preds, y_train, lrbase_test_preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression w/ RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MP</th>\n",
       "      <th>FG</th>\n",
       "      <th>2P</th>\n",
       "      <th>FT</th>\n",
       "      <th>TRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PTS</th>\n",
       "      <th>roy</th>\n",
       "      <th>...</th>\n",
       "      <th>USG%_3</th>\n",
       "      <th>ORtg_3</th>\n",
       "      <th>DRtg_3</th>\n",
       "      <th>OWS_3</th>\n",
       "      <th>DWS_3</th>\n",
       "      <th>WS/48_3</th>\n",
       "      <th>VORP_3</th>\n",
       "      <th>VORP_1-2</th>\n",
       "      <th>VORP_2-3</th>\n",
       "      <th>season_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.943454</td>\n",
       "      <td>0.947423</td>\n",
       "      <td>0.398373</td>\n",
       "      <td>1.540453</td>\n",
       "      <td>-0.401482</td>\n",
       "      <td>1.771461</td>\n",
       "      <td>0.673271</td>\n",
       "      <td>0.993256</td>\n",
       "      <td>1.293784</td>\n",
       "      <td>-0.183037</td>\n",
       "      <td>...</td>\n",
       "      <td>1.520879</td>\n",
       "      <td>0.902097</td>\n",
       "      <td>0.867052</td>\n",
       "      <td>2.176889</td>\n",
       "      <td>-0.224027</td>\n",
       "      <td>0.974407</td>\n",
       "      <td>1.689118</td>\n",
       "      <td>-0.366980</td>\n",
       "      <td>1.791781</td>\n",
       "      <td>1.362916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.096102</td>\n",
       "      <td>0.022652</td>\n",
       "      <td>-0.220105</td>\n",
       "      <td>-0.225004</td>\n",
       "      <td>0.571891</td>\n",
       "      <td>-0.502083</td>\n",
       "      <td>-0.122284</td>\n",
       "      <td>-0.489410</td>\n",
       "      <td>0.058572</td>\n",
       "      <td>-0.183037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055443</td>\n",
       "      <td>0.049858</td>\n",
       "      <td>-0.983774</td>\n",
       "      <td>-0.287171</td>\n",
       "      <td>0.884982</td>\n",
       "      <td>0.535562</td>\n",
       "      <td>-0.221069</td>\n",
       "      <td>1.082430</td>\n",
       "      <td>-0.884010</td>\n",
       "      <td>0.906549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-0.500480</td>\n",
       "      <td>-0.729920</td>\n",
       "      <td>-0.876000</td>\n",
       "      <td>-0.998549</td>\n",
       "      <td>-1.014415</td>\n",
       "      <td>0.061605</td>\n",
       "      <td>-0.568570</td>\n",
       "      <td>-0.598030</td>\n",
       "      <td>-0.742134</td>\n",
       "      <td>-0.183037</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.084431</td>\n",
       "      <td>-1.181154</td>\n",
       "      <td>1.052135</td>\n",
       "      <td>-0.938054</td>\n",
       "      <td>-1.333036</td>\n",
       "      <td>-1.595971</td>\n",
       "      <td>-1.282284</td>\n",
       "      <td>-0.125411</td>\n",
       "      <td>-1.205105</td>\n",
       "      <td>0.176361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>-0.769544</td>\n",
       "      <td>-0.793698</td>\n",
       "      <td>-0.735137</td>\n",
       "      <td>-0.802387</td>\n",
       "      <td>-0.677760</td>\n",
       "      <td>-0.558452</td>\n",
       "      <td>-0.432744</td>\n",
       "      <td>-0.983632</td>\n",
       "      <td>-0.825250</td>\n",
       "      <td>-0.183037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.799817</td>\n",
       "      <td>0.333938</td>\n",
       "      <td>0.867052</td>\n",
       "      <td>-0.333662</td>\n",
       "      <td>-0.620102</td>\n",
       "      <td>-0.310782</td>\n",
       "      <td>-0.362564</td>\n",
       "      <td>-0.246196</td>\n",
       "      <td>-0.134788</td>\n",
       "      <td>-0.553828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>-0.127002</td>\n",
       "      <td>-0.100651</td>\n",
       "      <td>-0.211301</td>\n",
       "      <td>-0.169487</td>\n",
       "      <td>-0.474668</td>\n",
       "      <td>-0.158501</td>\n",
       "      <td>-0.015563</td>\n",
       "      <td>-0.402514</td>\n",
       "      <td>-0.075564</td>\n",
       "      <td>-0.183037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075917</td>\n",
       "      <td>0.902097</td>\n",
       "      <td>1.237217</td>\n",
       "      <td>0.038271</td>\n",
       "      <td>-0.936962</td>\n",
       "      <td>0.222101</td>\n",
       "      <td>-0.150321</td>\n",
       "      <td>1.323998</td>\n",
       "      <td>-0.884010</td>\n",
       "      <td>-0.280007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           MP        FG        2P        FT       TRB       AST       STL  \\\n",
       "490  0.943454  0.947423  0.398373  1.540453 -0.401482  1.771461  0.673271   \n",
       "405  0.096102  0.022652 -0.220105 -0.225004  0.571891 -0.502083 -0.122284   \n",
       "156 -0.500480 -0.729920 -0.876000 -0.998549 -1.014415  0.061605 -0.568570   \n",
       "650 -0.769544 -0.793698 -0.735137 -0.802387 -0.677760 -0.558452 -0.432744   \n",
       "770 -0.127002 -0.100651 -0.211301 -0.169487 -0.474668 -0.158501 -0.015563   \n",
       "\n",
       "          TOV       PTS       roy  ...    USG%_3    ORtg_3    DRtg_3  \\\n",
       "490  0.993256  1.293784 -0.183037  ...  1.520879  0.902097  0.867052   \n",
       "405 -0.489410  0.058572 -0.183037  ... -0.055443  0.049858 -0.983774   \n",
       "156 -0.598030 -0.742134 -0.183037  ... -1.084431 -1.181154  1.052135   \n",
       "650 -0.983632 -0.825250 -0.183037  ... -0.799817  0.333938  0.867052   \n",
       "770 -0.402514 -0.075564 -0.183037  ...  0.075917  0.902097  1.237217   \n",
       "\n",
       "        OWS_3     DWS_3   WS/48_3    VORP_3  VORP_1-2  VORP_2-3  season_year  \n",
       "490  2.176889 -0.224027  0.974407  1.689118 -0.366980  1.791781     1.362916  \n",
       "405 -0.287171  0.884982  0.535562 -0.221069  1.082430 -0.884010     0.906549  \n",
       "156 -0.938054 -1.333036 -1.595971 -1.282284 -0.125411 -1.205105     0.176361  \n",
       "650 -0.333662 -0.620102 -0.310782 -0.362564 -0.246196 -0.134788    -0.553828  \n",
       "770  0.038271 -0.936962  0.222101 -0.150321  1.323998 -0.884010    -0.280007  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['2P', 'TRB', 'PTS', 'spg_1', 'tpg_1', 'MP_2', 'bpg_2', 'PER_2', 'MP_3',\n",
       "       'TS%_3', 'spg_3', 'PER_3', 'VORP_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_lr = RFECV(estimator=LogisticRegression(class_weight = 'balanced', max_iter = 1000), step = 1, cv = 3, scoring = 'precision', n_jobs = -1, verbose = 1)\n",
    "rfe_lr.fit(X_train_sc, y_train)\n",
    "X_train_sc.columns[rfe_lr.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cols = ['2P', 'TRB', 'PTS', 'spg_1', 'tpg_1', 'MP_2', 'bpg_2', 'PER_2', 'MP_3',\n",
    "       'TS%_3', 'spg_3', 'PER_3', 'VORP_3', 'season_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2P</th>\n",
       "      <th>TRB</th>\n",
       "      <th>PTS</th>\n",
       "      <th>spg_1</th>\n",
       "      <th>tpg_1</th>\n",
       "      <th>MP_2</th>\n",
       "      <th>bpg_2</th>\n",
       "      <th>PER_2</th>\n",
       "      <th>MP_3</th>\n",
       "      <th>TS%_3</th>\n",
       "      <th>spg_3</th>\n",
       "      <th>PER_3</th>\n",
       "      <th>VORP_3</th>\n",
       "      <th>season_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2P</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.752948</td>\n",
       "      <td>0.961977</td>\n",
       "      <td>0.564395</td>\n",
       "      <td>0.700540</td>\n",
       "      <td>0.794024</td>\n",
       "      <td>0.327550</td>\n",
       "      <td>0.627135</td>\n",
       "      <td>0.759072</td>\n",
       "      <td>0.287028</td>\n",
       "      <td>0.558332</td>\n",
       "      <td>0.596094</td>\n",
       "      <td>0.643094</td>\n",
       "      <td>-0.293510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRB</th>\n",
       "      <td>0.752948</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702601</td>\n",
       "      <td>0.333466</td>\n",
       "      <td>0.471621</td>\n",
       "      <td>0.669657</td>\n",
       "      <td>0.603728</td>\n",
       "      <td>0.545663</td>\n",
       "      <td>0.647238</td>\n",
       "      <td>0.310550</td>\n",
       "      <td>0.313820</td>\n",
       "      <td>0.517104</td>\n",
       "      <td>0.508001</td>\n",
       "      <td>-0.134946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTS</th>\n",
       "      <td>0.961977</td>\n",
       "      <td>0.702601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608713</td>\n",
       "      <td>0.733541</td>\n",
       "      <td>0.835116</td>\n",
       "      <td>0.259483</td>\n",
       "      <td>0.633662</td>\n",
       "      <td>0.796804</td>\n",
       "      <td>0.314160</td>\n",
       "      <td>0.603171</td>\n",
       "      <td>0.609791</td>\n",
       "      <td>0.694026</td>\n",
       "      <td>-0.180591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spg_1</th>\n",
       "      <td>0.564395</td>\n",
       "      <td>0.333466</td>\n",
       "      <td>0.608713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.757831</td>\n",
       "      <td>0.528539</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>0.370467</td>\n",
       "      <td>0.422597</td>\n",
       "      <td>0.089536</td>\n",
       "      <td>0.677636</td>\n",
       "      <td>0.337423</td>\n",
       "      <td>0.491409</td>\n",
       "      <td>-0.165677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tpg_1</th>\n",
       "      <td>0.700540</td>\n",
       "      <td>0.471621</td>\n",
       "      <td>0.733541</td>\n",
       "      <td>0.757831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557795</td>\n",
       "      <td>0.162851</td>\n",
       "      <td>0.414641</td>\n",
       "      <td>0.446124</td>\n",
       "      <td>0.116180</td>\n",
       "      <td>0.490676</td>\n",
       "      <td>0.379465</td>\n",
       "      <td>0.483027</td>\n",
       "      <td>-0.236445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MP_2</th>\n",
       "      <td>0.794024</td>\n",
       "      <td>0.669657</td>\n",
       "      <td>0.835116</td>\n",
       "      <td>0.528539</td>\n",
       "      <td>0.557795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.310852</td>\n",
       "      <td>0.535659</td>\n",
       "      <td>0.678924</td>\n",
       "      <td>0.211218</td>\n",
       "      <td>0.520144</td>\n",
       "      <td>0.409365</td>\n",
       "      <td>0.500771</td>\n",
       "      <td>-0.121784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpg_2</th>\n",
       "      <td>0.327550</td>\n",
       "      <td>0.603728</td>\n",
       "      <td>0.259483</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>0.162851</td>\n",
       "      <td>0.310852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350039</td>\n",
       "      <td>0.237106</td>\n",
       "      <td>0.121907</td>\n",
       "      <td>0.027747</td>\n",
       "      <td>0.275623</td>\n",
       "      <td>0.276091</td>\n",
       "      <td>-0.061570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER_2</th>\n",
       "      <td>0.627135</td>\n",
       "      <td>0.545663</td>\n",
       "      <td>0.633662</td>\n",
       "      <td>0.370467</td>\n",
       "      <td>0.414641</td>\n",
       "      <td>0.535659</td>\n",
       "      <td>0.350039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.488120</td>\n",
       "      <td>0.301426</td>\n",
       "      <td>0.415372</td>\n",
       "      <td>0.581705</td>\n",
       "      <td>0.566160</td>\n",
       "      <td>-0.046919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MP_3</th>\n",
       "      <td>0.759072</td>\n",
       "      <td>0.647238</td>\n",
       "      <td>0.796804</td>\n",
       "      <td>0.422597</td>\n",
       "      <td>0.446124</td>\n",
       "      <td>0.678924</td>\n",
       "      <td>0.237106</td>\n",
       "      <td>0.488120</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401441</td>\n",
       "      <td>0.643711</td>\n",
       "      <td>0.553914</td>\n",
       "      <td>0.659984</td>\n",
       "      <td>-0.092109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TS%_3</th>\n",
       "      <td>0.287028</td>\n",
       "      <td>0.310550</td>\n",
       "      <td>0.314160</td>\n",
       "      <td>0.089536</td>\n",
       "      <td>0.116180</td>\n",
       "      <td>0.211218</td>\n",
       "      <td>0.121907</td>\n",
       "      <td>0.301426</td>\n",
       "      <td>0.401441</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.237658</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.415196</td>\n",
       "      <td>-0.018562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spg_3</th>\n",
       "      <td>0.558332</td>\n",
       "      <td>0.313820</td>\n",
       "      <td>0.603171</td>\n",
       "      <td>0.677636</td>\n",
       "      <td>0.490676</td>\n",
       "      <td>0.520144</td>\n",
       "      <td>0.027747</td>\n",
       "      <td>0.415372</td>\n",
       "      <td>0.643711</td>\n",
       "      <td>0.237658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502415</td>\n",
       "      <td>0.657844</td>\n",
       "      <td>-0.148423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER_3</th>\n",
       "      <td>0.596094</td>\n",
       "      <td>0.517104</td>\n",
       "      <td>0.609791</td>\n",
       "      <td>0.337423</td>\n",
       "      <td>0.379465</td>\n",
       "      <td>0.409365</td>\n",
       "      <td>0.275623</td>\n",
       "      <td>0.581705</td>\n",
       "      <td>0.553914</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.502415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.710580</td>\n",
       "      <td>-0.014694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VORP_3</th>\n",
       "      <td>0.643094</td>\n",
       "      <td>0.508001</td>\n",
       "      <td>0.694026</td>\n",
       "      <td>0.491409</td>\n",
       "      <td>0.483027</td>\n",
       "      <td>0.500771</td>\n",
       "      <td>0.276091</td>\n",
       "      <td>0.566160</td>\n",
       "      <td>0.659984</td>\n",
       "      <td>0.415196</td>\n",
       "      <td>0.657844</td>\n",
       "      <td>0.710580</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.094867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season_year</th>\n",
       "      <td>-0.293510</td>\n",
       "      <td>-0.134946</td>\n",
       "      <td>-0.180591</td>\n",
       "      <td>-0.165677</td>\n",
       "      <td>-0.236445</td>\n",
       "      <td>-0.121784</td>\n",
       "      <td>-0.061570</td>\n",
       "      <td>-0.046919</td>\n",
       "      <td>-0.092109</td>\n",
       "      <td>-0.018562</td>\n",
       "      <td>-0.148423</td>\n",
       "      <td>-0.014694</td>\n",
       "      <td>-0.094867</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   2P       TRB       PTS     spg_1     tpg_1      MP_2  \\\n",
       "2P           1.000000  0.752948  0.961977  0.564395  0.700540  0.794024   \n",
       "TRB          0.752948  1.000000  0.702601  0.333466  0.471621  0.669657   \n",
       "PTS          0.961977  0.702601  1.000000  0.608713  0.733541  0.835116   \n",
       "spg_1        0.564395  0.333466  0.608713  1.000000  0.757831  0.528539   \n",
       "tpg_1        0.700540  0.471621  0.733541  0.757831  1.000000  0.557795   \n",
       "MP_2         0.794024  0.669657  0.835116  0.528539  0.557795  1.000000   \n",
       "bpg_2        0.327550  0.603728  0.259483  0.028762  0.162851  0.310852   \n",
       "PER_2        0.627135  0.545663  0.633662  0.370467  0.414641  0.535659   \n",
       "MP_3         0.759072  0.647238  0.796804  0.422597  0.446124  0.678924   \n",
       "TS%_3        0.287028  0.310550  0.314160  0.089536  0.116180  0.211218   \n",
       "spg_3        0.558332  0.313820  0.603171  0.677636  0.490676  0.520144   \n",
       "PER_3        0.596094  0.517104  0.609791  0.337423  0.379465  0.409365   \n",
       "VORP_3       0.643094  0.508001  0.694026  0.491409  0.483027  0.500771   \n",
       "season_year -0.293510 -0.134946 -0.180591 -0.165677 -0.236445 -0.121784   \n",
       "\n",
       "                bpg_2     PER_2      MP_3     TS%_3     spg_3     PER_3  \\\n",
       "2P           0.327550  0.627135  0.759072  0.287028  0.558332  0.596094   \n",
       "TRB          0.603728  0.545663  0.647238  0.310550  0.313820  0.517104   \n",
       "PTS          0.259483  0.633662  0.796804  0.314160  0.603171  0.609791   \n",
       "spg_1        0.028762  0.370467  0.422597  0.089536  0.677636  0.337423   \n",
       "tpg_1        0.162851  0.414641  0.446124  0.116180  0.490676  0.379465   \n",
       "MP_2         0.310852  0.535659  0.678924  0.211218  0.520144  0.409365   \n",
       "bpg_2        1.000000  0.350039  0.237106  0.121907  0.027747  0.275623   \n",
       "PER_2        0.350039  1.000000  0.488120  0.301426  0.415372  0.581705   \n",
       "MP_3         0.237106  0.488120  1.000000  0.401441  0.643711  0.553914   \n",
       "TS%_3        0.121907  0.301426  0.401441  1.000000  0.237658  0.630986   \n",
       "spg_3        0.027747  0.415372  0.643711  0.237658  1.000000  0.502415   \n",
       "PER_3        0.275623  0.581705  0.553914  0.630986  0.502415  1.000000   \n",
       "VORP_3       0.276091  0.566160  0.659984  0.415196  0.657844  0.710580   \n",
       "season_year -0.061570 -0.046919 -0.092109 -0.018562 -0.148423 -0.014694   \n",
       "\n",
       "               VORP_3  season_year  \n",
       "2P           0.643094    -0.293510  \n",
       "TRB          0.508001    -0.134946  \n",
       "PTS          0.694026    -0.180591  \n",
       "spg_1        0.491409    -0.165677  \n",
       "tpg_1        0.483027    -0.236445  \n",
       "MP_2         0.500771    -0.121784  \n",
       "bpg_2        0.276091    -0.061570  \n",
       "PER_2        0.566160    -0.046919  \n",
       "MP_3         0.659984    -0.092109  \n",
       "TS%_3        0.415196    -0.018562  \n",
       "spg_3        0.657844    -0.148423  \n",
       "PER_3        0.710580    -0.014694  \n",
       "VORP_3       1.000000    -0.094867  \n",
       "season_year -0.094867     1.000000  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc[lr_cols].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRB</th>\n",
       "      <th>PTS</th>\n",
       "      <th>spg_1</th>\n",
       "      <th>tpg_1</th>\n",
       "      <th>MP_2</th>\n",
       "      <th>bpg_2</th>\n",
       "      <th>PER_2</th>\n",
       "      <th>MP_3</th>\n",
       "      <th>TS%_3</th>\n",
       "      <th>spg_3</th>\n",
       "      <th>PER_3</th>\n",
       "      <th>VORP_3</th>\n",
       "      <th>season_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TRB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.702601</td>\n",
       "      <td>0.333466</td>\n",
       "      <td>0.471621</td>\n",
       "      <td>0.669657</td>\n",
       "      <td>0.603728</td>\n",
       "      <td>0.545663</td>\n",
       "      <td>0.647238</td>\n",
       "      <td>0.310550</td>\n",
       "      <td>0.313820</td>\n",
       "      <td>0.517104</td>\n",
       "      <td>0.508001</td>\n",
       "      <td>-0.134946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTS</th>\n",
       "      <td>0.702601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608713</td>\n",
       "      <td>0.733541</td>\n",
       "      <td>0.835116</td>\n",
       "      <td>0.259483</td>\n",
       "      <td>0.633662</td>\n",
       "      <td>0.796804</td>\n",
       "      <td>0.314160</td>\n",
       "      <td>0.603171</td>\n",
       "      <td>0.609791</td>\n",
       "      <td>0.694026</td>\n",
       "      <td>-0.180591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spg_1</th>\n",
       "      <td>0.333466</td>\n",
       "      <td>0.608713</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.757831</td>\n",
       "      <td>0.528539</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>0.370467</td>\n",
       "      <td>0.422597</td>\n",
       "      <td>0.089536</td>\n",
       "      <td>0.677636</td>\n",
       "      <td>0.337423</td>\n",
       "      <td>0.491409</td>\n",
       "      <td>-0.165677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tpg_1</th>\n",
       "      <td>0.471621</td>\n",
       "      <td>0.733541</td>\n",
       "      <td>0.757831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.557795</td>\n",
       "      <td>0.162851</td>\n",
       "      <td>0.414641</td>\n",
       "      <td>0.446124</td>\n",
       "      <td>0.116180</td>\n",
       "      <td>0.490676</td>\n",
       "      <td>0.379465</td>\n",
       "      <td>0.483027</td>\n",
       "      <td>-0.236445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MP_2</th>\n",
       "      <td>0.669657</td>\n",
       "      <td>0.835116</td>\n",
       "      <td>0.528539</td>\n",
       "      <td>0.557795</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.310852</td>\n",
       "      <td>0.535659</td>\n",
       "      <td>0.678924</td>\n",
       "      <td>0.211218</td>\n",
       "      <td>0.520144</td>\n",
       "      <td>0.409365</td>\n",
       "      <td>0.500771</td>\n",
       "      <td>-0.121784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bpg_2</th>\n",
       "      <td>0.603728</td>\n",
       "      <td>0.259483</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>0.162851</td>\n",
       "      <td>0.310852</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350039</td>\n",
       "      <td>0.237106</td>\n",
       "      <td>0.121907</td>\n",
       "      <td>0.027747</td>\n",
       "      <td>0.275623</td>\n",
       "      <td>0.276091</td>\n",
       "      <td>-0.061570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER_2</th>\n",
       "      <td>0.545663</td>\n",
       "      <td>0.633662</td>\n",
       "      <td>0.370467</td>\n",
       "      <td>0.414641</td>\n",
       "      <td>0.535659</td>\n",
       "      <td>0.350039</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.488120</td>\n",
       "      <td>0.301426</td>\n",
       "      <td>0.415372</td>\n",
       "      <td>0.581705</td>\n",
       "      <td>0.566160</td>\n",
       "      <td>-0.046919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MP_3</th>\n",
       "      <td>0.647238</td>\n",
       "      <td>0.796804</td>\n",
       "      <td>0.422597</td>\n",
       "      <td>0.446124</td>\n",
       "      <td>0.678924</td>\n",
       "      <td>0.237106</td>\n",
       "      <td>0.488120</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401441</td>\n",
       "      <td>0.643711</td>\n",
       "      <td>0.553914</td>\n",
       "      <td>0.659984</td>\n",
       "      <td>-0.092109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TS%_3</th>\n",
       "      <td>0.310550</td>\n",
       "      <td>0.314160</td>\n",
       "      <td>0.089536</td>\n",
       "      <td>0.116180</td>\n",
       "      <td>0.211218</td>\n",
       "      <td>0.121907</td>\n",
       "      <td>0.301426</td>\n",
       "      <td>0.401441</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.237658</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.415196</td>\n",
       "      <td>-0.018562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spg_3</th>\n",
       "      <td>0.313820</td>\n",
       "      <td>0.603171</td>\n",
       "      <td>0.677636</td>\n",
       "      <td>0.490676</td>\n",
       "      <td>0.520144</td>\n",
       "      <td>0.027747</td>\n",
       "      <td>0.415372</td>\n",
       "      <td>0.643711</td>\n",
       "      <td>0.237658</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502415</td>\n",
       "      <td>0.657844</td>\n",
       "      <td>-0.148423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER_3</th>\n",
       "      <td>0.517104</td>\n",
       "      <td>0.609791</td>\n",
       "      <td>0.337423</td>\n",
       "      <td>0.379465</td>\n",
       "      <td>0.409365</td>\n",
       "      <td>0.275623</td>\n",
       "      <td>0.581705</td>\n",
       "      <td>0.553914</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.502415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.710580</td>\n",
       "      <td>-0.014694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VORP_3</th>\n",
       "      <td>0.508001</td>\n",
       "      <td>0.694026</td>\n",
       "      <td>0.491409</td>\n",
       "      <td>0.483027</td>\n",
       "      <td>0.500771</td>\n",
       "      <td>0.276091</td>\n",
       "      <td>0.566160</td>\n",
       "      <td>0.659984</td>\n",
       "      <td>0.415196</td>\n",
       "      <td>0.657844</td>\n",
       "      <td>0.710580</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.094867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>season_year</th>\n",
       "      <td>-0.134946</td>\n",
       "      <td>-0.180591</td>\n",
       "      <td>-0.165677</td>\n",
       "      <td>-0.236445</td>\n",
       "      <td>-0.121784</td>\n",
       "      <td>-0.061570</td>\n",
       "      <td>-0.046919</td>\n",
       "      <td>-0.092109</td>\n",
       "      <td>-0.018562</td>\n",
       "      <td>-0.148423</td>\n",
       "      <td>-0.014694</td>\n",
       "      <td>-0.094867</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  TRB       PTS     spg_1     tpg_1      MP_2     bpg_2  \\\n",
       "TRB          1.000000  0.702601  0.333466  0.471621  0.669657  0.603728   \n",
       "PTS          0.702601  1.000000  0.608713  0.733541  0.835116  0.259483   \n",
       "spg_1        0.333466  0.608713  1.000000  0.757831  0.528539  0.028762   \n",
       "tpg_1        0.471621  0.733541  0.757831  1.000000  0.557795  0.162851   \n",
       "MP_2         0.669657  0.835116  0.528539  0.557795  1.000000  0.310852   \n",
       "bpg_2        0.603728  0.259483  0.028762  0.162851  0.310852  1.000000   \n",
       "PER_2        0.545663  0.633662  0.370467  0.414641  0.535659  0.350039   \n",
       "MP_3         0.647238  0.796804  0.422597  0.446124  0.678924  0.237106   \n",
       "TS%_3        0.310550  0.314160  0.089536  0.116180  0.211218  0.121907   \n",
       "spg_3        0.313820  0.603171  0.677636  0.490676  0.520144  0.027747   \n",
       "PER_3        0.517104  0.609791  0.337423  0.379465  0.409365  0.275623   \n",
       "VORP_3       0.508001  0.694026  0.491409  0.483027  0.500771  0.276091   \n",
       "season_year -0.134946 -0.180591 -0.165677 -0.236445 -0.121784 -0.061570   \n",
       "\n",
       "                PER_2      MP_3     TS%_3     spg_3     PER_3    VORP_3  \\\n",
       "TRB          0.545663  0.647238  0.310550  0.313820  0.517104  0.508001   \n",
       "PTS          0.633662  0.796804  0.314160  0.603171  0.609791  0.694026   \n",
       "spg_1        0.370467  0.422597  0.089536  0.677636  0.337423  0.491409   \n",
       "tpg_1        0.414641  0.446124  0.116180  0.490676  0.379465  0.483027   \n",
       "MP_2         0.535659  0.678924  0.211218  0.520144  0.409365  0.500771   \n",
       "bpg_2        0.350039  0.237106  0.121907  0.027747  0.275623  0.276091   \n",
       "PER_2        1.000000  0.488120  0.301426  0.415372  0.581705  0.566160   \n",
       "MP_3         0.488120  1.000000  0.401441  0.643711  0.553914  0.659984   \n",
       "TS%_3        0.301426  0.401441  1.000000  0.237658  0.630986  0.415196   \n",
       "spg_3        0.415372  0.643711  0.237658  1.000000  0.502415  0.657844   \n",
       "PER_3        0.581705  0.553914  0.630986  0.502415  1.000000  0.710580   \n",
       "VORP_3       0.566160  0.659984  0.415196  0.657844  0.710580  1.000000   \n",
       "season_year -0.046919 -0.092109 -0.018562 -0.148423 -0.014694 -0.094867   \n",
       "\n",
       "             season_year  \n",
       "TRB            -0.134946  \n",
       "PTS            -0.180591  \n",
       "spg_1          -0.165677  \n",
       "tpg_1          -0.236445  \n",
       "MP_2           -0.121784  \n",
       "bpg_2          -0.061570  \n",
       "PER_2          -0.046919  \n",
       "MP_3           -0.092109  \n",
       "TS%_3          -0.018562  \n",
       "spg_3          -0.148423  \n",
       "PER_3          -0.014694  \n",
       "VORP_3         -0.094867  \n",
       "season_year     1.000000  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping features that are over .9 correlated with eachother (2P)\n",
    "\n",
    "lr_cols = ['TRB', 'PTS', 'spg_1', 'tpg_1', 'MP_2', 'bpg_2', 'PER_2', 'MP_3',\n",
    "       'TS%_3', 'spg_3', 'PER_3', 'VORP_3', 'season_year']\n",
    "\n",
    "X_train_sc[lr_cols].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression w/ RFE Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\t0.9528 \tTesting Accuracy:\t0.9451\n",
      "Training Precision:\t0.7609 \tTesting Precision:\t0.625\n",
      "Training Recall:\t0.4861 \tTesting Recall:\t\t0.5556\n",
      "Training F1:\t\t0.5932 \tTesting F1:\t\t0.5882\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(class_weight = 'balance', random_state = 42)\n",
    "lr.fit(X_train_sc[lr_cols], y_train)\n",
    "\n",
    "lrbaserfe_train_preds = lr.predict(X_train_sc[lr_cols])\n",
    "lrbaserfe_test_preds = lr.predict(X_test_sc[lr_cols])\n",
    "metrics_score(lrbaserfe_train_preds, y_train, lrbaserfe_test_preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression w/ RFE & Grid-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed:    1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\t0.9086 \tTesting Accuracy:\t0.8824\n",
      "Training Precision:\t0.4323 \tTesting Precision:\t0.3571\n",
      "Training Recall:\t0.9306 \tTesting Recall:\t\t0.8333\n",
      "Training F1:\t\t0.5903 \tTesting F1:\t\t0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    3.0s finished\n"
     ]
    }
   ],
   "source": [
    "C = np.logspace(0, 1, 10)\n",
    "\n",
    "params = dict(C=C, max_iter=[50, 100], class_weight = ['balanced', None])\n",
    "\n",
    "logistic = LogisticRegression(penalty='l2', random_state=42)\n",
    "\n",
    "grid_search_LR = GridSearchCV(estimator = logistic,scoring=scorer, param_grid = params, \n",
    "                              cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search_LR.fit(X_train_sc[lr_cols], y_train)\n",
    "\n",
    "lrgsrfe_train_preds = grid_search_LR.best_estimator_.predict(X_train_sc[lr_cols])\n",
    "lrgsrfe_test_preds = grid_search_LR.best_estimator_.predict(X_test_sc[lr_cols])\n",
    "metrics_score(lrgsrfe_train_preds, y_train, lrgsrfe_test_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "fig.suptitle(\"Logistic Regression Classifier Model\")\n",
    "\n",
    "plot_confusion_matrix(grid_search_LR, X_test_sc[lr_cols], y_test, ax=ax, cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:    1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\t0.9419 \tTesting Accuracy:\t0.8941\n",
      "Training Precision:\t0.9197 \tTesting Precision:\t0.3784\n",
      "Training Recall:\t0.9683 \tTesting Recall:\t\t0.7778\n",
      "Training F1:\t\t0.9434 \tTesting F1:\t\t0.5091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state = 42)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train_sc[lr_cols], y_train.ravel())\n",
    "\n",
    "C = np.logspace(0, 1, 10)\n",
    "\n",
    "params = dict(C=C, max_iter=[50, 100], class_weight = ['balanced', None])\n",
    "\n",
    "logistic = LogisticRegression(penalty='l2', random_state=42)\n",
    "\n",
    "grid_search_LR_sm = GridSearchCV(estimator = logistic,scoring=scorer, param_grid = params, \n",
    "                              cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search_LR_sm.fit(X_train_res, y_train_res)\n",
    "\n",
    "lr_train_preds_sm = grid_search_LR_sm.best_estimator_.predict(X_train_res)\n",
    "lr_test_preds_sm = grid_search_LR_sm.best_estimator_.predict(X_test_sc[lr_cols])\n",
    "metrics_score(lr_train_preds_sm, y_train_res, lr_test_preds_sm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Modeling\n",
    "\n",
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\t1.0 \tTesting Accuracy:\t0.9098\n",
      "Training Precision:\t1.0 \tTesting Precision:\t0.3684\n",
      "Training Recall:\t1.0 \tTesting Recall:\t\t0.3889\n",
      "Training F1:\t\t1.0 \tTesting F1:\t\t0.3784\n"
     ]
    }
   ],
   "source": [
    "DT = tree.DecisionTreeClassifier(random_state = 42, class_weight = 'balanced')\n",
    "\n",
    "\n",
    "DT.fit(X_train_sc, y_train)\n",
    "\n",
    "dt_train_preds = DT.predict(X_train_sc)\n",
    "dt_test_preds = DT.predict(X_test_sc)\n",
    "metrics_score(dt_train_preds, y_train, dt_test_preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Decision Tree model is very overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFE w/ Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n",
      "Fitting estimator with 10 features.\n",
      "Fitting estimator with 9 features.\n",
      "Fitting estimator with 8 features.\n",
      "Fitting estimator with 7 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['FT', 'PER_1', 'VORP_2', 'rpg_3', 'spg_3', 'PER_3'], dtype='object')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe_dt = RFECV(estimator=tree.DecisionTreeClassifier(class_weight = 'balanced'), step = 1, cv = 3, scoring = 'precision', n_jobs = -1, verbose = 1)\n",
    "rfe_dt.fit(X_train_sc, y_train)\n",
    "X_train_sc.columns[rfe_dt.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_cols = ['FT', 'PER_1', 'WS_2', 'GS_2', 'VORP_2', 'rpg_3', 'spg_3', 'PER_3', 'season_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\t1.0 \tTesting Accuracy:\t0.898\n",
      "Training Precision:\t1.0 \tTesting Precision:\t0.3182\n",
      "Training Recall:\t1.0 \tTesting Recall:\t\t0.3889\n",
      "Training F1:\t\t1.0 \tTesting F1:\t\t0.35\n"
     ]
    }
   ],
   "source": [
    "DT = tree.DecisionTreeClassifier(random_state = 42, class_weight = 'balanced')\n",
    "DT.fit(X_train_sc[dt_cols], y_train)\n",
    "\n",
    "DTbaserfe_train_preds = DT.predict(X_train_sc[dt_cols])\n",
    "DTbaserfe_test_preds = DT.predict(X_test_sc[dt_cols])\n",
    "metrics_score(DTbaserfe_train_preds, y_train, DTbaserfe_test_preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline with RFE still very over fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree w/ RFE + Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    1.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\t0.8978 \tTesting Accuracy:\t0.8706\n",
      "Training Precision:\t0.4024 \tTesting Precision:\t0.3333\n",
      "Training Recall:\t0.9167 \tTesting Recall:\t\t0.8333\n",
      "Training F1:\t\t0.5593 \tTesting F1:\t\t0.4762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    1.3s finished\n"
     ]
    }
   ],
   "source": [
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2,4,6,8,10,12]\n",
    "\n",
    "params = dict(criterion=['gini', 'entropy'],\n",
    "                max_depth=[2,4,6,8,10,12,15,20,25],\n",
    "                 splitter = ['best', 'random'],\n",
    "             )\n",
    "\n",
    "DT = tree.DecisionTreeClassifier(random_state = 42, class_weight = 'balanced')\n",
    "\n",
    "grid_search_DT = GridSearchCV(estimator=DT, param_grid=params, scoring=scorer, \n",
    "                              cv = 5, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search_DT.fit(X_train_sc[dt_cols], y_train)\n",
    "\n",
    "dtrfegs_train_preds = grid_search_DT.best_estimator_.predict(X_train_sc[dt_cols])\n",
    "dtrfegs_test_preds = grid_search_DT.best_estimator_.predict(X_test_sc[dt_cols])\n",
    "metrics_score(dtrfegs_train_preds, y_train, dtrfegs_test_preds, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree w/ RFE + Grid Search + Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:\t0.9921 \tTesting Accuracy:\t0.9137\n",
      "Training Precision:\t0.9854 \tTesting Precision:\t0.4231\n",
      "Training Recall:\t0.9989 \tTesting Recall:\t\t0.6111\n",
      "Training F1:\t\t0.9921 \tTesting F1:\t\t0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state = 42)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train_sc[dt_cols], y_train.ravel())\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "max_depth = [2,4,6,8,10,12]\n",
    "\n",
    "params = dict(criterion=['gini', 'entropy'],\n",
    "                max_depth=[2,4,6,8,10,12,15,20,25],\n",
    "                 splitter = ['best', 'random'],\n",
    "             )\n",
    "\n",
    "DT = tree.DecisionTreeClassifier(random_state = 42, class_weight = 'balanced')\n",
    "\n",
    "grid_search_DT_sm = GridSearchCV(estimator=DT, param_grid=params, scoring=scorer, \n",
    "                              cv = 5, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search_DT_sm.fit(X_train_res, y_train_res)\n",
    "\n",
    "dtrfegssm_train_preds = grid_search_DT_sm.best_estimator_.predict(X_train_res)\n",
    "dtrfegssm_test_preds = grid_search_DT_sm.best_estimator_.predict(X_test_sc[dt_cols])\n",
    "metrics_score(dtrfegssm_train_preds, y_train_res, dtrfegssm_test_preds, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_candidates = [\n",
    "    \n",
    "    {'name':'Logistic Regression',\n",
    "     'accuracy score':accuracy_score(y_test, lrgsrfe_test_preds),\n",
    "     'recall score' : recall_score(y_test, lrgsrfe_test_preds),\n",
    "     'precision score' : precision_score(y_test,lrgsrfe_test_preds),\n",
    "         'f1 score':metrics.f1_score(y_test, lrgsrfe_test_preds)},\n",
    "    \n",
    "    {'name':'Logistic Regression w/ Resampling',\n",
    "     'accuracy score':accuracy_score(y_test, lr_test_preds_sm),\n",
    "     'recall score' : recall_score(y_test, lr_test_preds_sm),\n",
    "     'precision score' : precision_score(y_test,lr_test_preds_sm),\n",
    "     'f1 score':metrics.f1_score(y_test, lr_test_preds_sm)},\n",
    "    \n",
    "    {'name':'Random Forest',\n",
    "     'accuracy score':accuracy_score(y_test, rf_test_preds),\n",
    "     'recall score' : recall_score(y_test, rf_test_preds,),\n",
    "     'precision score' : precision_score(y_test,rf_test_preds),\n",
    "    'f1 score':metrics.f1_score(y_test, rf_test_preds)},\n",
    "    \n",
    "    {'name':'Random Forest w/ Resampling',\n",
    "     'accuracy score':accuracy_score(y_test, rf_test_preds_sm),\n",
    "     'recall score' : recall_score(y_test, rf_test_preds_sm),\n",
    "     'precision score' : precision_score(y_test,rf_test_preds_sm),\n",
    "     'f1 score':metrics.f1_score(y_test, rf_test_preds_sm)},\n",
    "    \n",
    "    {'name':'Decision Tree',\n",
    "     'accuracy score':accuracy_score(y_test, dtrfegs_test_preds),\n",
    "     'recall score' : recall_score(y_test, dtrfegs_test_preds),\n",
    "     'precision score' : precision_score(y_test,dtrfegs_test_preds),\n",
    "     'f1 score':metrics.f1_score(y_test, dtrfegs_test_preds)},\n",
    "    \n",
    "    {'name':'Decision Tree w/ Resampling',\n",
    "     'accuracy score':accuracy_score(y_test, dtrfegssm_test_preds),\n",
    "     'recall score' : recall_score(y_test, dtrfegssm_test_preds),\n",
    "     'precision score' : precision_score(y_test,dtrfegssm_test_preds),\n",
    "     'f1 score':metrics.f1_score(y_test, dtrfegssm_test_preds)},\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy score</th>\n",
       "      <th>recall score</th>\n",
       "      <th>precision score</th>\n",
       "      <th>f1 score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression w/ Resampling</th>\n",
       "      <td>0.894118</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.378378</td>\n",
       "      <td>0.509091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.952941</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest w/ Resampling</th>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree w/ Resampling</th>\n",
       "      <td>0.913725</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   accuracy score  recall score  \\\n",
       "name                                                              \n",
       "Logistic Regression                      0.882353      0.833333   \n",
       "Logistic Regression w/ Resampling        0.894118      0.777778   \n",
       "Random Forest                            0.952941      0.500000   \n",
       "Random Forest w/ Resampling              0.921569      0.722222   \n",
       "Decision Tree                            0.870588      0.833333   \n",
       "Decision Tree w/ Resampling              0.913725      0.611111   \n",
       "\n",
       "                                   precision score  f1 score  \n",
       "name                                                          \n",
       "Logistic Regression                       0.357143  0.500000  \n",
       "Logistic Regression w/ Resampling         0.378378  0.509091  \n",
       "Random Forest                             0.750000  0.600000  \n",
       "Random Forest w/ Resampling               0.464286  0.565217  \n",
       "Decision Tree                             0.333333  0.476190  \n",
       "Decision Tree w/ Resampling               0.423077  0.500000  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_scores_df = pd.DataFrame(model_candidates).set_index('name')\n",
    "final_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
